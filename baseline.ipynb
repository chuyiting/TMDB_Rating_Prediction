{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e87c794",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5680ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "movies_path = \"dataset/tmdb_5000_movies.csv\"\n",
    "credits_path = \"dataset/tmdb_5000_credits.csv\"\n",
    "\n",
    "movies = pd.read_csv(movies_path)\n",
    "credits = pd.read_csv(credits_path)\n",
    "\n",
    "data = movies.copy()\n",
    "data = data.dropna(subset=[\"vote_average\", \"overview\"])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    data,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3c0eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360, 20)\n",
      "Index(['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language',\n",
      "       'original_title', 'overview', 'popularity', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'vote_average',\n",
      "       'vote_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a80152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "TOP_K_CAST = 5      \n",
    "TOP_N_ACTORS = 100  \n",
    "\n",
    "def parse_cast(cast_str):\n",
    "    if pd.isna(cast_str):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(cast_str)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_top_k_actors(cast_list, k):\n",
    "    if not isinstance(cast_list, list):\n",
    "        return []\n",
    "    cast_sorted = sorted(cast_list, key=lambda x: x.get(\"order\", 1e9))\n",
    "    top_k = cast_sorted[:k]\n",
    "    return [member.get(\"name\") for member in top_k if \"name\" in member]\n",
    "\n",
    "\n",
    "credits_parsed = credits.copy()\n",
    "credits_parsed[\"cast_parsed\"] = credits_parsed[\"cast\"].apply(parse_cast)\n",
    "\n",
    "records = []\n",
    "for row in credits_parsed.itertuples(index=False):\n",
    "    movie_id = row.movie_id\n",
    "    top_actors = get_top_k_actors(row.cast_parsed, TOP_K_CAST)\n",
    "    for actor_name in top_actors:\n",
    "        records.append({\"movie_id\": movie_id, \"actor_name\": actor_name})\n",
    "\n",
    "top_cast_df = pd.DataFrame(records)\n",
    "\n",
    "movie_ratings = data[[\"id\", \"vote_average\"]].rename(columns={\"id\": \"movie_id\"})\n",
    "merged = top_cast_df.merge(movie_ratings, on=\"movie_id\", how=\"inner\")\n",
    "\n",
    "actor_counts = merged[\"actor_name\"].value_counts()\n",
    "\n",
    "top_actor_names = actor_counts.head(TOP_N_ACTORS).index\n",
    "filtered = merged[merged[\"actor_name\"].isin(top_actor_names)]\n",
    "\n",
    "actor_stats = (\n",
    "    filtered\n",
    "    .groupby(\"actor_name\")\n",
    "    .agg(\n",
    "        n_movies=(\"movie_id\", \"nunique\"),    \n",
    "        appearances=(\"movie_id\", \"size\"),    \n",
    "        mean_rating=(\"vote_average\", \"mean\"), \n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\"mean_rating\", ascending=False)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb919cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 actors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_name</th>\n",
       "      <th>n_movies</th>\n",
       "      <th>appearances</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Leonardo DiCaprio</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>7.072727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Tom Hanks</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>7.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Brad Pitt</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>6.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.786957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Philip Seymour Hoffman</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>6.777273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Mark Ruffalo</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>6.768182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ed Harris</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>6.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Denzel Washington</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>6.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Christopher Plummer</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>6.723077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Ralph Fiennes</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>6.696000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                actor_name  n_movies  appearances  mean_rating\n",
       "63       Leonardo DiCaprio        22           22     7.072727\n",
       "94               Tom Hanks        29           29     7.051724\n",
       "13               Brad Pitt        32           32     6.812500\n",
       "19          Christian Bale        23           23     6.786957\n",
       "77  Philip Seymour Hoffman        22           22     6.777273\n",
       "65            Mark Ruffalo        22           22     6.768182\n",
       "29               Ed Harris        25           25     6.756000\n",
       "25       Denzel Washington        30           30     6.730000\n",
       "20     Christopher Plummer        26           26     6.723077\n",
       "79           Ralph Fiennes        25           25     6.696000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 Actors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_name</th>\n",
       "      <th>n_movies</th>\n",
       "      <th>appearances</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Will Ferrell</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>6.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Nicolas Cage</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>5.988571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dwayne Johnson</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>5.985714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>John Travolta</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>5.985185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Sandler</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>5.970833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Paul Rudd</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>5.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Sylvester Stallone</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>5.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Owen Wilson</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>5.848387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Eddie Murphy</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Justin Long</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>5.619048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            actor_name  n_movies  appearances  mean_rating\n",
       "96        Will Ferrell        28           28     6.017857\n",
       "73        Nicolas Cage        35           35     5.988571\n",
       "28      Dwayne Johnson        21           21     5.985714\n",
       "52       John Travolta        27           27     5.985185\n",
       "0         Adam Sandler        24           24     5.970833\n",
       "76           Paul Rudd        24           24     5.958333\n",
       "92  Sylvester Stallone        27           27     5.888889\n",
       "75         Owen Wilson        31           31     5.848387\n",
       "30        Eddie Murphy        28           28     5.800000\n",
       "57         Justin Long        21           21     5.619048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Best 10 actors\")\n",
    "display(actor_stats.head(10))\n",
    "\n",
    "print(\"Worst 10 Actors\")\n",
    "display(actor_stats.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b0e89",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36475ecf",
   "metadata": {},
   "source": [
    "### Build the feature vectors for each movie:\n",
    "Turns the overview text into a bag-of-words representation:\n",
    "Top 500 most frequent words (after English stop-word removal).\n",
    "Each word is a binary feature (1 = word appears in the overview, 0 = does not).\n",
    "\n",
    "Adds 4 numeric features:\n",
    "**budget**, **popularity**, **runtime**\n",
    "Standardized (zero mean, unit variance) using StandardScaler.\n",
    "Concatenate text features and numeric features into a single sparse matrix:\n",
    "First 500 dimensions = text features (overview words)\n",
    "Last 4 dimensions = numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063e9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "TOP_K_CAST = 5      \n",
    "TOP_N_ACTORS = 100  \n",
    "\n",
    "\n",
    "def parse_cast(cast_str):\n",
    "    if pd.isna(cast_str):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(cast_str)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_top_k_actors(cast_list, k):\n",
    "    if not isinstance(cast_list, list):\n",
    "        return []\n",
    "    cast_sorted = sorted(cast_list, key=lambda x: x.get(\"order\", 1e9))\n",
    "    top_k = cast_sorted[:k]\n",
    "    return [m.get(\"name\") for m in top_k if \"name\" in m]\n",
    "\n",
    "\n",
    "def build_cast_features(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    credits_df,\n",
    "    top_k_cast=5,\n",
    "    top_n_actors=100,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build one-hot actor features for each movie.\n",
    "    Length = top_n_actors; 1 if actor is in top_k_cast for that movie.\n",
    "    \"\"\"\n",
    "\n",
    "    credits_parsed = credits_df.copy()\n",
    "    credits_parsed[\"cast_parsed\"] = credits_parsed[\"cast\"].apply(parse_cast)\n",
    "\n",
    "    movie_to_actors = {}\n",
    "    records = []\n",
    "    for row in credits_parsed.itertuples(index=False):\n",
    "        movie_id = row.movie_id\n",
    "        top_actors = get_top_k_actors(row.cast_parsed, top_k_cast)\n",
    "        movie_to_actors[movie_id] = top_actors\n",
    "        for name in top_actors:\n",
    "            records.append((movie_id, name))\n",
    "\n",
    "    cast_df = pd.DataFrame(records, columns=[\"movie_id\", \"actor_name\"])\n",
    "\n",
    "    actor_counts = cast_df[\"actor_name\"].value_counts()\n",
    "    top_actor_names = list(actor_counts.head(top_n_actors).index)\n",
    "    actor_to_idx = {name: i for i, name in enumerate(top_actor_names)}\n",
    "\n",
    "    def make_matrix(df):\n",
    "        n = len(df)\n",
    "        mat = np.zeros((n, len(top_actor_names)), dtype=np.float32)\n",
    "        movie_ids = df[\"id\"].values  # TMDB movie id in movies.csv\n",
    "        for i, mid in enumerate(movie_ids):\n",
    "            actors = movie_to_actors.get(mid, [])\n",
    "            for name in actors:\n",
    "                j = actor_to_idx.get(name)\n",
    "                if j is not None:\n",
    "                    mat[i, j] = 1.0\n",
    "        return csr_matrix(mat)\n",
    "\n",
    "    X_train = make_matrix(train_df)\n",
    "    X_val = make_matrix(val_df)\n",
    "    X_test = make_matrix(test_df)\n",
    "\n",
    "    feature_names = np.array([f\"cast__{name}\" for name in top_actor_names])\n",
    "    return (X_train, X_val, X_test), feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b0583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_overview_features(train_df, val_df, test_df, max_features=500):\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=max_features,\n",
    "        binary=True,\n",
    "        stop_words=\"english\",\n",
    "    )\n",
    "    X_train = vectorizer.fit_transform(train_df[\"overview\"])\n",
    "    X_val = vectorizer.transform(val_df[\"overview\"])\n",
    "    X_test = vectorizer.transform(test_df[\"overview\"])\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    feature_names = np.array([f\"overview__{w}\" for w in words])\n",
    "    return (X_train, X_val, X_test), feature_names, vectorizer\n",
    "\n",
    "\n",
    "def build_numeric_features(train_df, val_df, test_df, cols):\n",
    "    for col in cols:\n",
    "        if col not in train_df.columns:\n",
    "            train_df[col] = 0.0\n",
    "            val_df[col] = 0.0\n",
    "            test_df[col] = 0.0\n",
    "    numeric_train = train_df[cols].fillna(0.0).values.astype(float)\n",
    "    numeric_val = val_df[cols].fillna(0.0).values.astype(float)\n",
    "    numeric_test = test_df[cols].fillna(0.0).values.astype(float)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    numeric_train_scaled = scaler.fit_transform(numeric_train)\n",
    "    numeric_val_scaled = scaler.transform(numeric_val)\n",
    "    numeric_test_scaled = scaler.transform(numeric_test)\n",
    "\n",
    "    X_train = csr_matrix(numeric_train_scaled)\n",
    "    X_val = csr_matrix(numeric_val_scaled)\n",
    "    X_test = csr_matrix(numeric_test_scaled)\n",
    "    feature_names = np.array(cols)\n",
    "    return (X_train, X_val, X_test), feature_names, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa9701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "def build_overview_features(train_df, val_df, test_df, max_features=500):\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=max_features,\n",
    "        binary=True,\n",
    "        stop_words=\"english\"\n",
    "    )\n",
    "    X_train = vectorizer.fit_transform(train_df[\"overview\"])\n",
    "    X_val = vectorizer.transform(val_df[\"overview\"])\n",
    "    X_test = vectorizer.transform(test_df[\"overview\"])\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    feature_names = np.array([f\"overview__{w}\" for w in words])\n",
    "    return (X_train, X_val, X_test), feature_names, vectorizer\n",
    "\n",
    "def build_numeric_features(train_df, val_df, test_df, cols):\n",
    "    for col in cols:\n",
    "        if col not in train_df.columns:\n",
    "            train_df[col] = 0.0\n",
    "            val_df[col] = 0.0\n",
    "            test_df[col] = 0.0\n",
    "    numeric_train = train_df[cols].fillna(0.0).values.astype(float)\n",
    "    numeric_val = val_df[cols].fillna(0.0).values.astype(float)\n",
    "    numeric_test = test_df[cols].fillna(0.0).values.astype(float)\n",
    "    scaler = StandardScaler()\n",
    "    numeric_train_scaled = scaler.fit_transform(numeric_train)\n",
    "    numeric_val_scaled = scaler.transform(numeric_val)\n",
    "    numeric_test_scaled = scaler.transform(numeric_test)\n",
    "    X_train = csr_matrix(numeric_train_scaled)\n",
    "    X_val = csr_matrix(numeric_val_scaled)\n",
    "    X_test = csr_matrix(numeric_test_scaled)\n",
    "    feature_names = np.array(cols)\n",
    "    return (X_train, X_val, X_test), feature_names, scaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def build_features(train_df, val_df, test_df, max_overview_features, numeric_cols, verbose=False):\n",
    "    feature_blocks_train = []\n",
    "    feature_blocks_val = []\n",
    "    feature_blocks_test = []\n",
    "    feature_name_blocks = []\n",
    "\n",
    "    (overview_train, overview_val, overview_test), overview_feature_names, overview_vectorizer = build_overview_features(\n",
    "        train_df, val_df, test_df, max_features=max_overview_features\n",
    "    )\n",
    "    feature_blocks_train.append(overview_train)\n",
    "    feature_blocks_val.append(overview_val)\n",
    "    feature_blocks_test.append(overview_test)\n",
    "    feature_name_blocks.append(overview_feature_names)\n",
    "\n",
    "    if len(numeric_cols) > 0:\n",
    "        (numeric_train_sparse, numeric_val_sparse, numeric_test_sparse), numeric_feature_names, numeric_scaler = build_numeric_features(\n",
    "            train_df, val_df, test_df, numeric_cols\n",
    "        )\n",
    "        feature_blocks_train.append(numeric_train_sparse)\n",
    "        feature_blocks_val.append(numeric_val_sparse)\n",
    "        feature_blocks_test.append(numeric_test_sparse)\n",
    "        feature_name_blocks.append(numeric_feature_names)\n",
    "    else:\n",
    "        numeric_feature_names = np.array([])\n",
    "\n",
    "    X_train = hstack(feature_blocks_train).tocsr()\n",
    "    X_val = hstack(feature_blocks_val).tocsr()\n",
    "    X_test = hstack(feature_blocks_test).tocsr()\n",
    "\n",
    "    feature_names = np.concatenate(feature_name_blocks)\n",
    "\n",
    "    y_train = train_df[\"vote_average\"].values\n",
    "    y_val = val_df[\"vote_average\"].values\n",
    "    y_test = test_df[\"vote_average\"].values\n",
    "\n",
    "    global_mean_rating = y_train.mean()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"X_train shape:\", X_train.shape)\n",
    "        print(\"X_val shape:\", X_val.shape)\n",
    "        print(\"X_test shape:\", X_test.shape)\n",
    "        print()\n",
    "        print(\"Total number of features:\", X_train.shape[1])\n",
    "        print(\"Number of text features:\", len(overview_feature_names))\n",
    "        print(\"Number of numeric features:\", len(numeric_feature_names))\n",
    "        print()\n",
    "        print(\"First 20 feature names:\")\n",
    "        print(feature_names[:20])\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_val\": X_val,\n",
    "        \"X_test\": X_test,\n",
    "        \"overview_train\": overview_train,\n",
    "        \"overview_val\": overview_val,\n",
    "        \"overview_test\": overview_test,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"overview_feature_names\": overview_feature_names,\n",
    "        \"numeric_feature_names\": numeric_feature_names,\n",
    "        \"overview_vectorizer\": overview_vectorizer,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\": y_val,\n",
    "        \"y_test\": y_test,\n",
    "        \"global_mean_rating\": global_mean_rating,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "400679e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    max_overview_features,\n",
    "    numeric_cols,\n",
    "    use_cast=False,\n",
    "    top_k_cast=TOP_K_CAST,\n",
    "    top_n_actors=TOP_N_ACTORS,\n",
    "    verbose=False,\n",
    "):\n",
    "    feature_blocks_train = []\n",
    "    feature_blocks_val = []\n",
    "    feature_blocks_test = []\n",
    "    feature_name_blocks = []\n",
    "\n",
    "    # Text features (overview)\n",
    "    (overview_train, overview_val, overview_test), overview_feature_names, overview_vectorizer = (\n",
    "        build_overview_features(\n",
    "            train_df,\n",
    "            val_df,\n",
    "            test_df,\n",
    "            max_features=max_overview_features,\n",
    "        )\n",
    "    )\n",
    "    feature_blocks_train.append(overview_train)\n",
    "    feature_blocks_val.append(overview_val)\n",
    "    feature_blocks_test.append(overview_test)\n",
    "    feature_name_blocks.append(overview_feature_names)\n",
    "\n",
    "    # Numeric features\n",
    "    if len(numeric_cols) > 0:\n",
    "        (numeric_train_sparse, numeric_val_sparse, numeric_test_sparse), numeric_feature_names, numeric_scaler = (\n",
    "            build_numeric_features(\n",
    "                train_df,\n",
    "                val_df,\n",
    "                test_df,\n",
    "                numeric_cols,\n",
    "            )\n",
    "        )\n",
    "        feature_blocks_train.append(numeric_train_sparse)\n",
    "        feature_blocks_val.append(numeric_val_sparse)\n",
    "        feature_blocks_test.append(numeric_test_sparse)\n",
    "        feature_name_blocks.append(numeric_feature_names)\n",
    "    else:\n",
    "        numeric_feature_names = np.array([])\n",
    "\n",
    "    # Cast one-hot features (top-N actors, only if enabled)\n",
    "    if use_cast:\n",
    "        (cast_train, cast_val, cast_test), cast_feature_names = build_cast_features(\n",
    "            train_df,\n",
    "            val_df,\n",
    "            test_df,\n",
    "            credits,\n",
    "            top_k_cast=top_k_cast,\n",
    "            top_n_actors=top_n_actors,\n",
    "        )\n",
    "        feature_blocks_train.append(cast_train)\n",
    "        feature_blocks_val.append(cast_val)\n",
    "        feature_blocks_test.append(cast_test)\n",
    "        feature_name_blocks.append(cast_feature_names)\n",
    "    else:\n",
    "        cast_feature_names = np.array([])\n",
    "\n",
    "    # Combine all blocks\n",
    "    X_train = hstack(feature_blocks_train).tocsr()\n",
    "    X_val = hstack(feature_blocks_val).tocsr()\n",
    "    X_test = hstack(feature_blocks_test).tocsr()\n",
    "\n",
    "    feature_names = np.concatenate(feature_name_blocks)\n",
    "\n",
    "    y_train = train_df[\"vote_average\"].values\n",
    "    y_val = val_df[\"vote_average\"].values\n",
    "    y_test = test_df[\"vote_average\"].values\n",
    "\n",
    "    global_mean_rating = y_train.mean()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"X_train shape:\", X_train.shape)\n",
    "        print(\"X_val shape:\", X_val.shape)\n",
    "        print(\"X_test shape:\", X_test.shape)\n",
    "        print()\n",
    "        print(\"Total number of features:\", X_train.shape[1])\n",
    "        print(\"Number of text features:\", len(overview_feature_names))\n",
    "        print(\"Number of numeric features:\", len(numeric_feature_names))\n",
    "        print(\"Number of cast features:\", len(cast_feature_names))\n",
    "        print()\n",
    "        print(\"First 20 feature names:\")\n",
    "        print(feature_names[:20])\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_val\": X_val,\n",
    "        \"X_test\": X_test,\n",
    "        \"overview_train\": overview_train,\n",
    "        \"overview_val\": overview_val,\n",
    "        \"overview_test\": overview_test,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"overview_feature_names\": overview_feature_names,\n",
    "        \"numeric_feature_names\": numeric_feature_names,\n",
    "        \"cast_feature_names\": cast_feature_names,\n",
    "        \"overview_vectorizer\": overview_vectorizer,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\": y_val,\n",
    "        \"y_test\": y_test,\n",
    "        \"global_mean_rating\": global_mean_rating,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3360, 203)\n",
      "X_val shape: (720, 203)\n",
      "X_test shape: (720, 203)\n",
      "\n",
      "Total number of features: 203\n",
      "Number of text features: 200\n",
      "Number of numeric features: 3\n",
      "Number of cast features: 0\n",
      "\n",
      "First 20 feature names:\n",
      "['overview__accident' 'overview__action' 'overview__adventure'\n",
      " 'overview__agent' 'overview__america' 'overview__american'\n",
      " 'overview__angeles' 'overview__army' 'overview__attempt' 'overview__away'\n",
      " 'overview__based' 'overview__battle' 'overview__beautiful'\n",
      " 'overview__begin' 'overview__begins' 'overview__best' 'overview__big'\n",
      " 'overview__black' 'overview__boy' 'overview__british']\n"
     ]
    }
   ],
   "source": [
    "feats = build_features(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    max_overview_features=200,\n",
    "    numeric_cols=[\"budget\", \"popularity\", \"runtime\"],\n",
    "    use_cast=False,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe0472d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3360, 303)\n",
      "X_val shape: (720, 303)\n",
      "X_test shape: (720, 303)\n",
      "\n",
      "Total number of features: 303\n",
      "Number of text features: 200\n",
      "Number of numeric features: 3\n",
      "Number of cast features: 100\n",
      "\n",
      "First 20 feature names:\n",
      "['overview__accident' 'overview__action' 'overview__adventure'\n",
      " 'overview__agent' 'overview__america' 'overview__american'\n",
      " 'overview__angeles' 'overview__army' 'overview__attempt' 'overview__away'\n",
      " 'overview__based' 'overview__battle' 'overview__beautiful'\n",
      " 'overview__begin' 'overview__begins' 'overview__best' 'overview__big'\n",
      " 'overview__black' 'overview__boy' 'overview__british']\n"
     ]
    }
   ],
   "source": [
    "feats = build_features(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    max_overview_features=200,\n",
    "    numeric_cols=[\"budget\", \"popularity\", \"runtime\"],\n",
    "    use_cast=True,\n",
    "    top_k_cast=TOP_K_CAST,\n",
    "    top_n_actors=TOP_N_ACTORS,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016fcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_matrix(X_query, X_ref):\n",
    "    return cosine_similarity(X_query, X_ref)\n",
    "\n",
    "def weighted_average_predict(sim_matrix, y_train, k=20, global_mean=None):\n",
    "    if global_mean is None:\n",
    "        global_mean = float(np.mean(y_train))\n",
    "    n_query = sim_matrix.shape[0]\n",
    "    y_pred = np.empty(n_query, dtype=float)\n",
    "    for i in range(n_query):\n",
    "        sims = sim_matrix[i]\n",
    "        if k is not None and k < sims.shape[0]:\n",
    "            idx = np.argpartition(-sims, k)[:k]\n",
    "        else:\n",
    "            idx = np.arange(sims.shape[0])\n",
    "        neighbor_sims = sims[idx]\n",
    "        neighbor_ratings = y_train[idx]\n",
    "        positive = neighbor_sims > 0\n",
    "        if not np.any(positive):\n",
    "            y_pred[i] = global_mean\n",
    "        else:\n",
    "            weights = neighbor_sims[positive]\n",
    "            ratings = neighbor_ratings[positive]\n",
    "            y_pred[i] = np.sum(weights * ratings) / np.sum(weights)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc0c40",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d78c456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_features</th>\n",
       "      <th>numeric_config</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>0.921092</td>\n",
       "      <td>0.959735</td>\n",
       "      <td>0.669370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.316173</td>\n",
       "      <td>1.147246</td>\n",
       "      <td>0.794058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>0.986364</td>\n",
       "      <td>0.993159</td>\n",
       "      <td>0.715733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>0.852730</td>\n",
       "      <td>0.923434</td>\n",
       "      <td>0.682352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>0.949936</td>\n",
       "      <td>0.974647</td>\n",
       "      <td>0.689900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>all</td>\n",
       "      <td>1.007774</td>\n",
       "      <td>1.003880</td>\n",
       "      <td>0.690306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.343712</td>\n",
       "      <td>1.159186</td>\n",
       "      <td>0.815122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.081073</td>\n",
       "      <td>1.039747</td>\n",
       "      <td>0.731789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.124408</td>\n",
       "      <td>1.060381</td>\n",
       "      <td>0.743496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.045684</td>\n",
       "      <td>1.022587</td>\n",
       "      <td>0.712887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>all</td>\n",
       "      <td>1.049757</td>\n",
       "      <td>1.024576</td>\n",
       "      <td>0.697685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.346092</td>\n",
       "      <td>1.160212</td>\n",
       "      <td>0.816839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.095520</td>\n",
       "      <td>1.046671</td>\n",
       "      <td>0.735959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.186201</td>\n",
       "      <td>1.089129</td>\n",
       "      <td>0.751231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.055715</td>\n",
       "      <td>1.027480</td>\n",
       "      <td>0.708893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>all</td>\n",
       "      <td>1.066408</td>\n",
       "      <td>1.032671</td>\n",
       "      <td>0.722807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>400</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.353061</td>\n",
       "      <td>1.163211</td>\n",
       "      <td>0.814941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>400</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.113385</td>\n",
       "      <td>1.055171</td>\n",
       "      <td>0.760307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>400</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.146844</td>\n",
       "      <td>1.070908</td>\n",
       "      <td>0.755118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>400</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.083597</td>\n",
       "      <td>1.040959</td>\n",
       "      <td>0.739878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>800</td>\n",
       "      <td>all</td>\n",
       "      <td>1.097109</td>\n",
       "      <td>1.047430</td>\n",
       "      <td>0.743861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>800</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.330806</td>\n",
       "      <td>1.153606</td>\n",
       "      <td>0.806285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>800</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.145927</td>\n",
       "      <td>1.070480</td>\n",
       "      <td>0.772474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>800</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.153446</td>\n",
       "      <td>1.073986</td>\n",
       "      <td>0.776080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>800</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.127867</td>\n",
       "      <td>1.062011</td>\n",
       "      <td>0.753352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1200</td>\n",
       "      <td>all</td>\n",
       "      <td>1.106254</td>\n",
       "      <td>1.051786</td>\n",
       "      <td>0.745265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1200</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.340836</td>\n",
       "      <td>1.157945</td>\n",
       "      <td>0.805767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1200</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.165076</td>\n",
       "      <td>1.079387</td>\n",
       "      <td>0.780998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1200</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.151854</td>\n",
       "      <td>1.073245</td>\n",
       "      <td>0.772321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1200</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.139708</td>\n",
       "      <td>1.067571</td>\n",
       "      <td>0.762133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_features   numeric_config       MSE      RMSE       MAE\n",
       "0               1              all  0.921092  0.959735  0.669370\n",
       "1               1         drop_all  1.316173  1.147246  0.794058\n",
       "2               1      drop_budget  0.986364  0.993159  0.715733\n",
       "3               1     drop_runtime  0.852730  0.923434  0.682352\n",
       "4               1  drop_vote_count  0.949936  0.974647  0.689900\n",
       "5             100              all  1.007774  1.003880  0.690306\n",
       "6             100         drop_all  1.343712  1.159186  0.815122\n",
       "7             100      drop_budget  1.081073  1.039747  0.731789\n",
       "8             100     drop_runtime  1.124408  1.060381  0.743496\n",
       "9             100  drop_vote_count  1.045684  1.022587  0.712887\n",
       "10            200              all  1.049757  1.024576  0.697685\n",
       "11            200         drop_all  1.346092  1.160212  0.816839\n",
       "12            200      drop_budget  1.095520  1.046671  0.735959\n",
       "13            200     drop_runtime  1.186201  1.089129  0.751231\n",
       "14            200  drop_vote_count  1.055715  1.027480  0.708893\n",
       "15            400              all  1.066408  1.032671  0.722807\n",
       "16            400         drop_all  1.353061  1.163211  0.814941\n",
       "17            400      drop_budget  1.113385  1.055171  0.760307\n",
       "18            400     drop_runtime  1.146844  1.070908  0.755118\n",
       "19            400  drop_vote_count  1.083597  1.040959  0.739878\n",
       "20            800              all  1.097109  1.047430  0.743861\n",
       "21            800         drop_all  1.330806  1.153606  0.806285\n",
       "22            800      drop_budget  1.145927  1.070480  0.772474\n",
       "23            800     drop_runtime  1.153446  1.073986  0.776080\n",
       "24            800  drop_vote_count  1.127867  1.062011  0.753352\n",
       "25           1200              all  1.106254  1.051786  0.745265\n",
       "26           1200         drop_all  1.340836  1.157945  0.805767\n",
       "27           1200      drop_budget  1.165076  1.079387  0.780998\n",
       "28           1200     drop_runtime  1.151854  1.073245  0.772321\n",
       "29           1200  drop_vote_count  1.139708  1.067571  0.762133"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return mse, rmse, mae\n",
    "\n",
    "word_sizes = [1, 100, 200, 400, 800, 1200]\n",
    "\n",
    "numeric_configs = [\n",
    "    (\"all\", [\"budget\", \"popularity\", \"runtime\", \"vote_count\"]),\n",
    "    (\"drop_vote_count\", [\"budget\", \"popularity\", \"runtime\"]),\n",
    "    (\"drop_runtime\", [\"budget\", \"popularity\", \"vote_count\"]),\n",
    "    (\"drop_all\", []),\n",
    "    (\"drop_budget\", [\"popularity\", \"runtime\", \"vote_count\"]),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for max_words in word_sizes:\n",
    "    for numeric_name, numeric_cols in numeric_configs:\n",
    "        feats = build_features(\n",
    "            train_df,\n",
    "            val_df,\n",
    "            test_df,\n",
    "            max_overview_features=max_words,\n",
    "            numeric_cols=numeric_cols,\n",
    "            use_cast=True,\n",
    "            top_k_cast=TOP_K_CAST,\n",
    "            top_n_actors=TOP_N_ACTORS,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        X_train = feats[\"X_train\"]\n",
    "        X_val = feats[\"X_val\"]\n",
    "        overview_train = feats[\"overview_train\"]\n",
    "        overview_val = feats[\"overview_val\"]\n",
    "        y_train = feats[\"y_train\"]\n",
    "        y_val = feats[\"y_val\"]\n",
    "        global_mean_rating = feats[\"global_mean_rating\"]\n",
    "\n",
    "        cos_sim_val_train = cosine_similarity_matrix(X_val, X_train)\n",
    "        y_pred_cos = weighted_average_predict(\n",
    "            cos_sim_val_train,\n",
    "            y_train,\n",
    "            k=20,\n",
    "            global_mean=global_mean_rating\n",
    "        )\n",
    "        mse_cos, rmse_cos, mae_cos = compute_metrics(y_val, y_pred_cos)\n",
    "\n",
    "        rows.append({\n",
    "            \"word_features\": max_words,\n",
    "            \"numeric_config\": numeric_name,\n",
    "            \"MSE\": mse_cos,\n",
    "            \"RMSE\": rmse_cos,\n",
    "            \"MAE\": mae_cos,\n",
    "        })\n",
    "\n",
    "ablation_df = pd.DataFrame(rows)\n",
    "ablation_df.sort_values([\"word_features\", \"numeric_config\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a108a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
