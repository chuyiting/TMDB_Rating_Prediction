{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e87c794",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5680ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "movies_path = \"dataset/tmdb_5000_movies.csv\"\n",
    "credits_path = \"dataset/tmdb_5000_credits.csv\"\n",
    "\n",
    "movies = pd.read_csv(movies_path)\n",
    "credits = pd.read_csv(credits_path)\n",
    "\n",
    "data = movies.copy()\n",
    "data = data.dropna(subset=[\"vote_average\", \"overview\"])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    data,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3c0eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360, 20)\n",
      "Index(['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language',\n",
      "       'original_title', 'overview', 'popularity', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'vote_average',\n",
      "       'vote_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b0e89",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36475ecf",
   "metadata": {},
   "source": [
    "### Build the feature vectors for each movie:\n",
    "Turns the overview text into a bag-of-words representation:\n",
    "Top 500 most frequent words (after English stop-word removal).\n",
    "Each word is a binary feature (1 = word appears in the overview, 0 = does not).\n",
    "\n",
    "Adds 4 numeric features:\n",
    "**budget**, **popularity**, **runtime**\n",
    "Standardized (zero mean, unit variance) using StandardScaler.\n",
    "Concatenate text features and numeric features into a single sparse matrix:\n",
    "First 500 dimensions = text features (overview words)\n",
    "Last 4 dimensions = numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa9701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "def build_overview_features(train_df, val_df, test_df, max_features=500):\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=max_features,\n",
    "        binary=True,\n",
    "        stop_words=\"english\"\n",
    "    )\n",
    "    X_train = vectorizer.fit_transform(train_df[\"overview\"])\n",
    "    X_val = vectorizer.transform(val_df[\"overview\"])\n",
    "    X_test = vectorizer.transform(test_df[\"overview\"])\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    feature_names = np.array([f\"overview__{w}\" for w in words])\n",
    "    return (X_train, X_val, X_test), feature_names, vectorizer\n",
    "\n",
    "def build_numeric_features(train_df, val_df, test_df, cols):\n",
    "    for col in cols:\n",
    "        if col not in train_df.columns:\n",
    "            train_df[col] = 0.0\n",
    "            val_df[col] = 0.0\n",
    "            test_df[col] = 0.0\n",
    "    numeric_train = train_df[cols].fillna(0.0).values.astype(float)\n",
    "    numeric_val = val_df[cols].fillna(0.0).values.astype(float)\n",
    "    numeric_test = test_df[cols].fillna(0.0).values.astype(float)\n",
    "    scaler = StandardScaler()\n",
    "    numeric_train_scaled = scaler.fit_transform(numeric_train)\n",
    "    numeric_val_scaled = scaler.transform(numeric_val)\n",
    "    numeric_test_scaled = scaler.transform(numeric_test)\n",
    "    X_train = csr_matrix(numeric_train_scaled)\n",
    "    X_val = csr_matrix(numeric_val_scaled)\n",
    "    X_test = csr_matrix(numeric_test_scaled)\n",
    "    feature_names = np.array(cols)\n",
    "    return (X_train, X_val, X_test), feature_names, scaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def build_features(train_df, val_df, test_df, max_overview_features, numeric_cols, verbose=False):\n",
    "    feature_blocks_train = []\n",
    "    feature_blocks_val = []\n",
    "    feature_blocks_test = []\n",
    "    feature_name_blocks = []\n",
    "\n",
    "    (overview_train, overview_val, overview_test), overview_feature_names, overview_vectorizer = build_overview_features(\n",
    "        train_df, val_df, test_df, max_features=max_overview_features\n",
    "    )\n",
    "    feature_blocks_train.append(overview_train)\n",
    "    feature_blocks_val.append(overview_val)\n",
    "    feature_blocks_test.append(overview_test)\n",
    "    feature_name_blocks.append(overview_feature_names)\n",
    "\n",
    "    if len(numeric_cols) > 0:\n",
    "        (numeric_train_sparse, numeric_val_sparse, numeric_test_sparse), numeric_feature_names, numeric_scaler = build_numeric_features(\n",
    "            train_df, val_df, test_df, numeric_cols\n",
    "        )\n",
    "        feature_blocks_train.append(numeric_train_sparse)\n",
    "        feature_blocks_val.append(numeric_val_sparse)\n",
    "        feature_blocks_test.append(numeric_test_sparse)\n",
    "        feature_name_blocks.append(numeric_feature_names)\n",
    "    else:\n",
    "        numeric_feature_names = np.array([])\n",
    "\n",
    "    X_train = hstack(feature_blocks_train).tocsr()\n",
    "    X_val = hstack(feature_blocks_val).tocsr()\n",
    "    X_test = hstack(feature_blocks_test).tocsr()\n",
    "\n",
    "    feature_names = np.concatenate(feature_name_blocks)\n",
    "\n",
    "    y_train = train_df[\"vote_average\"].values\n",
    "    y_val = val_df[\"vote_average\"].values\n",
    "    y_test = test_df[\"vote_average\"].values\n",
    "\n",
    "    global_mean_rating = y_train.mean()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"X_train shape:\", X_train.shape)\n",
    "        print(\"X_val shape:\", X_val.shape)\n",
    "        print(\"X_test shape:\", X_test.shape)\n",
    "        print()\n",
    "        print(\"Total number of features:\", X_train.shape[1])\n",
    "        print(\"Number of text features:\", len(overview_feature_names))\n",
    "        print(\"Number of numeric features:\", len(numeric_feature_names))\n",
    "        print()\n",
    "        print(\"First 20 feature names:\")\n",
    "        print(feature_names[:20])\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_val\": X_val,\n",
    "        \"X_test\": X_test,\n",
    "        \"overview_train\": overview_train,\n",
    "        \"overview_val\": overview_val,\n",
    "        \"overview_test\": overview_test,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"overview_feature_names\": overview_feature_names,\n",
    "        \"numeric_feature_names\": numeric_feature_names,\n",
    "        \"overview_vectorizer\": overview_vectorizer,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\": y_val,\n",
    "        \"y_test\": y_test,\n",
    "        \"global_mean_rating\": global_mean_rating,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc61642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3360, 203)\n",
      "X_val shape: (720, 203)\n",
      "X_test shape: (720, 203)\n",
      "\n",
      "Total number of features: 203\n",
      "Number of text features: 200\n",
      "Number of numeric features: 3\n",
      "\n",
      "First 20 feature names:\n",
      "['overview__accident' 'overview__action' 'overview__adventure'\n",
      " 'overview__agent' 'overview__america' 'overview__american'\n",
      " 'overview__angeles' 'overview__army' 'overview__attempt' 'overview__away'\n",
      " 'overview__based' 'overview__battle' 'overview__beautiful'\n",
      " 'overview__begin' 'overview__begins' 'overview__best' 'overview__big'\n",
      " 'overview__black' 'overview__boy' 'overview__british']\n"
     ]
    }
   ],
   "source": [
    "feats = build_features(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    max_overview_features=200,\n",
    "    numeric_cols=[\"budget\", \"popularity\", \"runtime\"],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016fcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_matrix(X_query, X_ref):\n",
    "    return cosine_similarity(X_query, X_ref)\n",
    "\n",
    "def weighted_average_predict(sim_matrix, y_train, k=20, global_mean=None):\n",
    "    if global_mean is None:\n",
    "        global_mean = float(np.mean(y_train))\n",
    "    n_query = sim_matrix.shape[0]\n",
    "    y_pred = np.empty(n_query, dtype=float)\n",
    "    for i in range(n_query):\n",
    "        sims = sim_matrix[i]\n",
    "        if k is not None and k < sims.shape[0]:\n",
    "            idx = np.argpartition(-sims, k)[:k]\n",
    "        else:\n",
    "            idx = np.arange(sims.shape[0])\n",
    "        neighbor_sims = sims[idx]\n",
    "        neighbor_ratings = y_train[idx]\n",
    "        positive = neighbor_sims > 0\n",
    "        if not np.any(positive):\n",
    "            y_pred[i] = global_mean\n",
    "        else:\n",
    "            weights = neighbor_sims[positive]\n",
    "            ratings = neighbor_ratings[positive]\n",
    "            y_pred[i] = np.sum(weights * ratings) / np.sum(weights)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc0c40",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d78c456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_features</th>\n",
       "      <th>numeric_config</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>all</td>\n",
       "      <td>1.015266</td>\n",
       "      <td>1.007604</td>\n",
       "      <td>0.689959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.327912</td>\n",
       "      <td>1.152351</td>\n",
       "      <td>0.794432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.052835</td>\n",
       "      <td>1.026077</td>\n",
       "      <td>0.724144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.112336</td>\n",
       "      <td>1.054673</td>\n",
       "      <td>0.728012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.038510</td>\n",
       "      <td>1.019073</td>\n",
       "      <td>0.707575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>all</td>\n",
       "      <td>1.027442</td>\n",
       "      <td>1.013628</td>\n",
       "      <td>0.690299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.347282</td>\n",
       "      <td>1.160725</td>\n",
       "      <td>0.808208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.086291</td>\n",
       "      <td>1.042253</td>\n",
       "      <td>0.730124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.159565</td>\n",
       "      <td>1.076831</td>\n",
       "      <td>0.734692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.048237</td>\n",
       "      <td>1.023834</td>\n",
       "      <td>0.703956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>400</td>\n",
       "      <td>all</td>\n",
       "      <td>1.040975</td>\n",
       "      <td>1.020282</td>\n",
       "      <td>0.714223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>400</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.346643</td>\n",
       "      <td>1.160449</td>\n",
       "      <td>0.804597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.081179</td>\n",
       "      <td>1.039798</td>\n",
       "      <td>0.746936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.136757</td>\n",
       "      <td>1.066188</td>\n",
       "      <td>0.750334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>400</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.064520</td>\n",
       "      <td>1.031756</td>\n",
       "      <td>0.733311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>800</td>\n",
       "      <td>all</td>\n",
       "      <td>1.078744</td>\n",
       "      <td>1.038626</td>\n",
       "      <td>0.738465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>800</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.329386</td>\n",
       "      <td>1.152990</td>\n",
       "      <td>0.803625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>800</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.123587</td>\n",
       "      <td>1.059994</td>\n",
       "      <td>0.759720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>800</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.146421</td>\n",
       "      <td>1.070710</td>\n",
       "      <td>0.770491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>800</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.095151</td>\n",
       "      <td>1.046495</td>\n",
       "      <td>0.739026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1200</td>\n",
       "      <td>all</td>\n",
       "      <td>1.089890</td>\n",
       "      <td>1.043978</td>\n",
       "      <td>0.741903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1200</td>\n",
       "      <td>drop_all</td>\n",
       "      <td>1.352613</td>\n",
       "      <td>1.163019</td>\n",
       "      <td>0.804998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1200</td>\n",
       "      <td>drop_budget</td>\n",
       "      <td>1.140505</td>\n",
       "      <td>1.067944</td>\n",
       "      <td>0.770812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1200</td>\n",
       "      <td>drop_runtime</td>\n",
       "      <td>1.149182</td>\n",
       "      <td>1.071999</td>\n",
       "      <td>0.767304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1200</td>\n",
       "      <td>drop_vote_count</td>\n",
       "      <td>1.118771</td>\n",
       "      <td>1.057720</td>\n",
       "      <td>0.750369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_features   numeric_config       MSE      RMSE       MAE\n",
       "0             100              all  1.015266  1.007604  0.689959\n",
       "1             100         drop_all  1.327912  1.152351  0.794432\n",
       "2             100      drop_budget  1.052835  1.026077  0.724144\n",
       "3             100     drop_runtime  1.112336  1.054673  0.728012\n",
       "4             100  drop_vote_count  1.038510  1.019073  0.707575\n",
       "5             200              all  1.027442  1.013628  0.690299\n",
       "6             200         drop_all  1.347282  1.160725  0.808208\n",
       "7             200      drop_budget  1.086291  1.042253  0.730124\n",
       "8             200     drop_runtime  1.159565  1.076831  0.734692\n",
       "9             200  drop_vote_count  1.048237  1.023834  0.703956\n",
       "10            400              all  1.040975  1.020282  0.714223\n",
       "11            400         drop_all  1.346643  1.160449  0.804597\n",
       "12            400      drop_budget  1.081179  1.039798  0.746936\n",
       "13            400     drop_runtime  1.136757  1.066188  0.750334\n",
       "14            400  drop_vote_count  1.064520  1.031756  0.733311\n",
       "15            800              all  1.078744  1.038626  0.738465\n",
       "16            800         drop_all  1.329386  1.152990  0.803625\n",
       "17            800      drop_budget  1.123587  1.059994  0.759720\n",
       "18            800     drop_runtime  1.146421  1.070710  0.770491\n",
       "19            800  drop_vote_count  1.095151  1.046495  0.739026\n",
       "20           1200              all  1.089890  1.043978  0.741903\n",
       "21           1200         drop_all  1.352613  1.163019  0.804998\n",
       "22           1200      drop_budget  1.140505  1.067944  0.770812\n",
       "23           1200     drop_runtime  1.149182  1.071999  0.767304\n",
       "24           1200  drop_vote_count  1.118771  1.057720  0.750369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return mse, rmse, mae\n",
    "\n",
    "word_sizes = [100, 200, 400, 800, 1200]\n",
    "\n",
    "numeric_configs = [\n",
    "    (\"all\", [\"budget\", \"popularity\", \"runtime\", \"vote_count\"]),\n",
    "    (\"drop_vote_count\", [\"budget\", \"popularity\", \"runtime\"]),\n",
    "    (\"drop_runtime\", [\"budget\", \"popularity\", \"vote_count\"]),\n",
    "    (\"drop_all\", []),\n",
    "    (\"drop_budget\", [\"popularity\", \"runtime\", \"vote_count\"]),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for max_words in word_sizes:\n",
    "    for numeric_name, numeric_cols in numeric_configs:\n",
    "        feats = build_features(\n",
    "            train_df,\n",
    "            val_df,\n",
    "            test_df,\n",
    "            max_overview_features=max_words,\n",
    "            numeric_cols=numeric_cols,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        X_train = feats[\"X_train\"]\n",
    "        X_val = feats[\"X_val\"]\n",
    "        overview_train = feats[\"overview_train\"]\n",
    "        overview_val = feats[\"overview_val\"]\n",
    "        y_train = feats[\"y_train\"]\n",
    "        y_val = feats[\"y_val\"]\n",
    "        global_mean_rating = feats[\"global_mean_rating\"]\n",
    "\n",
    "        cos_sim_val_train = cosine_similarity_matrix(X_val, X_train)\n",
    "        y_pred_cos = weighted_average_predict(\n",
    "            cos_sim_val_train,\n",
    "            y_train,\n",
    "            k=20,\n",
    "            global_mean=global_mean_rating\n",
    "        )\n",
    "        mse_cos, rmse_cos, mae_cos = compute_metrics(y_val, y_pred_cos)\n",
    "\n",
    "        rows.append({\n",
    "            \"word_features\": max_words,\n",
    "            \"numeric_config\": numeric_name,\n",
    "            \"MSE\": mse_cos,\n",
    "            \"RMSE\": rmse_cos,\n",
    "            \"MAE\": mae_cos,\n",
    "        })\n",
    "\n",
    "ablation_df = pd.DataFrame(rows)\n",
    "ablation_df.sort_values([\"word_features\", \"numeric_config\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a108a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
